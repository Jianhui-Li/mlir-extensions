#map = affine_map<(@affine_map@) -> (@affine_map@)>
module attributes {torch.debug_module_name = "ReLU"} {

  llvm.mlir.global internal constant @str_global("the average kernel execution time (ms) over 100 runs: ")
  llvm.func @printCString(!llvm.ptr<i8>)
  llvm.func @printF64(f64)
  llvm.func @printNewline()
  llvm.func @rtclock() -> f64

  func.func @forward(%arg0: tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@> {
    %cst = arith.constant 0.000000e+00 : @dtype@
    %0 = tensor.empty() : tensor<@shape@x@dtype@>
    %1 = linalg.generic {indexing_maps = [#map, #map], iterator_types = [@iterator_types@]} ins(%arg0 : tensor<@shape@x@dtype@>) outs(%0 : tensor<@shape@x@dtype@>) {
    ^bb0(%in: @dtype@, %out: @dtype@):
      %2 = arith.cmpf ugt, %in, %cst : @dtype@
      %3 = arith.select %2, %in, %cst : @dtype@
      linalg.yield %3 : @dtype@
    } -> tensor<@shape@x@dtype@>
    return %1 : tensor<@shape@x@dtype@>
  }

  func.func @imex_cpu_profiler(%arg0: tensor<@shape@x@dtype@>) {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cM = arith.constant 5 : index
    %cN = arith.constant 200 : index
    %cNF = arith.constant 0.2 : f64
    %time_0 = arith.constant 0.0 : f64

    // Warm-up
    scf.for %i = %c0 to %cM step %c1 {
      %0 = func.call @forward(%arg0) : (tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@>
      %1 = bufferization.to_memref %0 : memref<@shape@x@dtype@>
      memref.dealloc %1: memref<@shape@x@dtype@>
    }


    // Profiling
    %time = scf.for %i = %c0 to %cN step %c1
            iter_args(%iter = %time_0) -> (f64) {
      %t0 = llvm.call @rtclock() : () -> f64
      %2 = func.call @forward(%arg0) : (tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@>
      %t1 = llvm.call @rtclock() : () -> f64
      %d = arith.subf %t1, %t0: f64
      %time_next = arith.addf %iter, %d: f64
      %3 = bufferization.to_memref %2 : memref<@shape@x@dtype@>
      memref.dealloc %3: memref<@shape@x@dtype@>
      scf.yield %time_next: f64
    }

    %avg = arith.divf %time, %cNF: f64

    %4 = llvm.mlir.addressof @str_global : !llvm.ptr<array<54 x i8>>
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.getelementptr %4[%5, %5] : (!llvm.ptr<array<54 x i8>>, i64, i64) -> !llvm.ptr<i8>

    llvm.call @printCString(%6) : (!llvm.ptr<i8>) -> ()
    llvm.call @printF64(%avg): (f64) -> ()
    llvm.call @printNewline(): () -> ()
    return
  }

  func.func @main() {
    %0= arith.constant dense<1.3>:tensor<@shape@x@dtype@>
    %1 = func.call @forward(%0) : (tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@>
    func.call @imex_cpu_profiler(%0) : (tensor<@shape@x@dtype@>) -> ()
    return
  }
}
