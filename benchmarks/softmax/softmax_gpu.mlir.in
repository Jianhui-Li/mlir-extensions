#map = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> (d0, 0)>
module attributes {torch.debug_module_name = "Softmax"} {
  func.func @forward(%arg0: tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@> {
    %c0_i64 = arith.constant 0 : i64
    %cst = arith.constant -3.40282347E+38 : @dtype@
    %cst_0 = arith.constant 0.000000e+00 : @dtype@
    %0 = tensor.empty() : tensor<@batch_size@x1xi64>
    %1 = linalg.fill ins(%c0_i64 : i64) outs(%0 : tensor<@batch_size@x1xi64>) -> tensor<@batch_size@x1xi64>
    %2 = tensor.empty() : tensor<@batch_size@x1x@dtype@>
    %3 = linalg.fill ins(%cst : @dtype@) outs(%2 : tensor<@batch_size@x1x@dtype@>) -> tensor<@batch_size@x1x@dtype@>
    %4:2 = linalg.generic {indexing_maps = [#map, #map1, #map1], iterator_types = ["parallel", "reduction"]} ins(%arg0 : tensor<@shape@x@dtype@>) outs(%3, %1 : tensor<@batch_size@x1x@dtype@>, tensor<@batch_size@x1xi64>) {
    ^bb0(%in: @dtype@, %out: @dtype@, %out_1: i64):
      %11 = linalg.index 1 : index
      %12 = arith.index_cast %11 : index to i64
      %13 = arith.maxf %in, %out : @dtype@
      %14 = arith.cmpf ogt, %in, %out : @dtype@
      %15 = arith.select %14, %12, %out_1 : i64
      linalg.yield %13, %15 : @dtype@, i64
    } -> (tensor<@batch_size@x1x@dtype@>, tensor<@batch_size@x1xi64>)
    %5 = tensor.empty() : tensor<@shape@x@dtype@>
    %6 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %4#0 : tensor<@shape@x@dtype@>, tensor<@batch_size@x1x@dtype@>) outs(%5 : tensor<@shape@x@dtype@>) {
    ^bb0(%in: @dtype@, %in_1: @dtype@, %out: @dtype@):
      %11 = arith.subf %in, %in_1 : @dtype@
      linalg.yield %11 : @dtype@
    } -> tensor<@shape@x@dtype@>
    %7 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel"]} ins(%6 : tensor<@shape@x@dtype@>) outs(%5 : tensor<@shape@x@dtype@>) {
    ^bb0(%in: @dtype@, %out: @dtype@):
      %11 = math.exp %in : @dtype@
      linalg.yield %11 : @dtype@
    } -> tensor<@shape@x@dtype@>
    %8 = linalg.fill ins(%cst_0 : @dtype@) outs(%2 : tensor<@batch_size@x1x@dtype@>) -> tensor<@batch_size@x1x@dtype@>
    %9 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "reduction"]} ins(%7 : tensor<@shape@x@dtype@>) outs(%8 : tensor<@batch_size@x1x@dtype@>) {
    ^bb0(%in: @dtype@, %out: @dtype@):
      %11 = arith.addf %in, %out : @dtype@
      linalg.yield %11 : @dtype@
    } -> tensor<@batch_size@x1x@dtype@>
    %10 = linalg.generic {indexing_maps = [#map, #map1, #map], iterator_types = ["parallel", "parallel"]} ins(%7, %9 : tensor<@shape@x@dtype@>, tensor<@batch_size@x1x@dtype@>) outs(%5 : tensor<@shape@x@dtype@>) {
    ^bb0(%in: @dtype@, %in_1: @dtype@, %out: @dtype@):
      %11 = arith.divf %in, %in_1 : @dtype@
      linalg.yield %11 : @dtype@
    } -> tensor<@shape@x@dtype@>
    return %10 : tensor<@shape@x@dtype@>
  }

  func.func @main() {
    %0= arith.constant dense<3.3>:tensor<@shape@x@dtype@>
    %1 = call @forward(%0) : (tensor<@shape@x@dtype@>) -> tensor<@shape@x@dtype@>
    return
  }
}
